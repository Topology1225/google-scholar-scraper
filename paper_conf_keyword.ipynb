{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, datetime, argparse\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import warnings,re\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import timeit\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 会議名，キーワードを設定\n",
    "会議名の略称と，正式名称両方を設定   \n",
    "\"キーワード 会議名の略称\"　で検索する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword0 = \"blind source separation\"\n",
    "keyword = keyword0.replace(' ', '+')\n",
    "key_conf = \"ICASSP\"\n",
    "conference = \"IEEE International Conference on Acoustics, Speech, and Signal Processing\"\n",
    "number = 10\n",
    "html_doc = requests.get(\"https://scholar.google.co.jp/scholar?hl=ja&as_sdt=0%2C5as_vis=1&num=\" + str(number) + \"&q=\" + keyword + \"+\" + key_conf).text\n",
    "soup = BeautifulSoup(html_doc, \"html.parser\") # BeautifulSoupの初期化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検索結果を会議名でフィルタリング\n",
    "キーワードを含む指定会議の論文を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1990, 1996]\n"
     ]
    }
   ],
   "source": [
    "tags2 = soup.find_all(\"div\", {\"class\": \"gs_a\"})\n",
    "thre_diff = 0.5\n",
    "conf_list =[]\n",
    "year_list = []\n",
    "for i in range(number):\n",
    "    conf = tags2[i].text\n",
    "    year = re.sub(r'\\D', '', conf)\n",
    "    conf = re.sub(r'\\d', '', conf)\n",
    "    diff = difflib.SequenceMatcher(None, conf, conference).ratio()\n",
    "    if diff > thre_diff:\n",
    "        conf_list.append(i)\n",
    "        year_list.append(int(year[0:4]))\n",
    "print(year_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得た論文の引用数を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[215, 156]\n"
     ]
    }
   ],
   "source": [
    "tags3 = soup.find_all(text=re.compile(\"引用元\")) \n",
    "ci_num_list = []\n",
    "for i in conf_list:\n",
    "    citations = tags3[i].replace(\"引用元\",\"\")\n",
    "    ci_num_list.append(int(citations))\n",
    "print(ci_num_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### それぞれの論文のIDを取得\n",
    "引用元をクロールするために必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12290659773686451132', '7647533509339401212']\n"
     ]
    }
   ],
   "source": [
    "tags4 = soup.find_all(\"div\", {\"class\": \"gs_fl\"})\n",
    "p_id_list = []\n",
    "for  i in conf_list:\n",
    "    try:\n",
    "        elem = elem = tags4[i*2+1].find_all('a')[2]['href']\n",
    "        a = 15\n",
    "        while True:\n",
    "            if elem[a] == '&':\n",
    "                break\n",
    "            a+=1\n",
    "        p_id_list.append(elem[15:a])\n",
    "    except:\n",
    "        print('')\n",
    "print(p_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
